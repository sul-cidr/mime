{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import imageio.v3 as iio\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from matplotlib import colormaps, colors\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import umap\n",
    "\n",
    "from mime_db import MimeDb\n",
    "from pose_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#video_fps = video_data[\"fps\"]\u001b[39;00m\n\u001b[1;32m     15\u001b[0m video_movelets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m db\u001b[38;5;241m.\u001b[39mget_movelet_data_from_video(video_id)\n\u001b[0;32m---> 16\u001b[0m movelets_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(video_movelets, columns\u001b[38;5;241m=\u001b[39m\u001b[43mvideo_movelets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     18\u001b[0m video_poses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m db\u001b[38;5;241m.\u001b[39mget_pose_data_from_video(video_id)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#video_poses = await db.get_poses_with_faces(video_id)\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "VIDEO_FILE = \"JuliusCaesarâ€”WinterMainStage23.mp4\" # Just the name of the video file, no path\n",
    "\n",
    "video_path = Path(\"videos\", VIDEO_FILE)\n",
    "\n",
    "# Connect to the database\n",
    "db = await MimeDb.create()\n",
    "\n",
    "# Get video metadata\n",
    "video_name = video_path.name\n",
    "video_id = await db.get_video_id(video_name)\n",
    "\n",
    "video_data = await db.get_video_by_id(video_id)\n",
    "video_fps = video_data[\"fps\"]\n",
    "\n",
    "video_movelets = await db.get_movelet_data_from_video(video_id)\n",
    "movelets_df = pd.DataFrame.from_records(video_movelets, columns=video_movelets[0].keys())\n",
    "\n",
    "video_poses = await db.get_pose_data_from_video(video_id)\n",
    "#video_poses = await db.get_poses_with_faces(video_id)\n",
    "\n",
    "poses_df = pd.DataFrame.from_records(video_poses, columns=video_poses[0].keys())\n",
    "\n",
    "print(poses_df.memory_usage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOTAL MOVELETS:\", len(movelets_df))\n",
    "print(\"NON-MOTION MOVELETS:\", len(movelets_df[movelets_df['movement'].isna()]))\n",
    "print(\"MOVELETS WITH STILL MOTION:\", len(movelets_df[movelets_df['movement'] == 0]))\n",
    "print(\"MOVELETS WITH MOVEMENT < 10px/sec:\", len(movelets_df[(movelets_df['movement'] >= 0) & (movelets_df['movement'] < 10)]))\n",
    "\n",
    "print(\"MEAN MOVEMENT PER MOVELET (norm px/sec):\", np.nanmean(movelets_df['movement']))\n",
    "print(\"MEDIAN MOVEMENT PER MOVELET (norm px/sec):\", np.nanmedian(movelets_df['movement']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonnull_movelets_df = movelets_df.copy()\n",
    "nonnull_movelets_df['movement'].fillna(-1, inplace=True)\n",
    "n, bins, patches = plt.hist(nonnull_movelets_df[nonnull_movelets_df['movement'] <= 500]['movement'], bins=300)\n",
    "plt.xlabel(\"Movement (normalized pixels/sec)\")\n",
    "plt.ylabel(\"# Movelets\")\n",
    "top_bin = n[1:].argmax()\n",
    "print('most frequent bin: (' + str(bins[top_bin]) + ',' + str(bins[top_bin+1]) + ')')\n",
    "print('mode: '+ str((bins[top_bin] + bins[top_bin+1])/2))\n",
    "movement_mode = (bins[top_bin] + bins[top_bin+1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_movelets = movelets_df[(movelets_df['movement'] >= 0) & (movelets_df['movement'] < movement_mode)].reset_index()\n",
    "frozen_poses = frozen_movelets['norm'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_embedding = umap.UMAP(\n",
    "    random_state=42,\n",
    ").fit_transform(frozen_poses)\n",
    "\n",
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], s=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterable_embedding = umap.UMAP(\n",
    "    n_neighbors=10,\n",
    "    min_dist=1.0,\n",
    "    n_components=2,\n",
    "    random_state=42,\n",
    ").fit_transform(frozen_poses)\n",
    "\n",
    "plt.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], s=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fitting clustering model\")\n",
    "\n",
    "hdb = HDBSCAN(min_cluster_size=3, min_samples=4) # , max_cluster_size=15\n",
    "hdb.fit(frozen_poses)\n",
    "labels = hdb.labels_.tolist()\n",
    "\n",
    "assigned_poses = 0\n",
    "\n",
    "cluster_to_poses = {}\n",
    "for i, cluster_id in enumerate(labels):\n",
    "    if cluster_id not in cluster_to_poses:\n",
    "        cluster_to_poses[cluster_id] = [i]\n",
    "    else:\n",
    "        cluster_to_poses[cluster_id].append(i)\n",
    "    \n",
    "tracks_per_cluster = []\n",
    "poses_per_track_per_cluster = []\n",
    "        \n",
    "for cluster_id in range(-1, max(labels) + 1):\n",
    "    #print(\"Poses in cluster\", cluster_id, labels.count(cluster_id))\n",
    "\n",
    "    cluster_track_poses = {}\n",
    "    for movelet_id in cluster_to_poses[cluster_id]:\n",
    "        movelet_track = frozen_movelets.iloc[movelet_id]['track_id']\n",
    "        if movelet_track not in cluster_track_poses:\n",
    "            cluster_track_poses[movelet_track] = 1\n",
    "        else:\n",
    "            cluster_track_poses[movelet_track] += 1\n",
    "            \n",
    "    if cluster_id != -1:\n",
    "        assigned_poses += labels.count(cluster_id)\n",
    "        tracks_per_cluster.append(len(cluster_track_poses))\n",
    "        poses_per_track_per_cluster.append(labels.count(cluster_id) / len(cluster_track_poses))\n",
    "    \n",
    "    #print(\"Tracks in cluster\", cluster_id, len(cluster_track_poses))\n",
    "\n",
    "print(\"assigned\", assigned_poses, \"poses out of\", len(labels), round(assigned_poses/len(labels),4))\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], c=labels, cmap='Spectral', s=4)\n",
    "\n",
    "fig2 = plt.figure(figsize=(10,4))\n",
    "ax = fig2.gca()\n",
    "n, bins, patches = plt.hist(tracks_per_cluster, bins=20)\n",
    "ax.set_title(\"Tracks per cluster\")\n",
    "ax.set_xlabel(\"# Tracks\")\n",
    "ax.set_ylabel(\"# Clusters\")\n",
    "plt.show()\n",
    "\n",
    "fig3 = plt.figure(figsize=(10,4))\n",
    "ax = fig3.gca()\n",
    "n, bins, patches = plt.hist(poses_per_track_per_cluster, bins=30)\n",
    "ax.set_title(\"Poses per track per cluster\")\n",
    "ax.set_xlabel(\"Poses/track\")\n",
    "ax.set_ylabel(\"# Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fitting UMAP preclustered model\")\n",
    "\n",
    "hdb = HDBSCAN(min_cluster_size=3, min_samples=4) # , max_cluster_size=15\n",
    "hdb.fit(clusterable_embedding)\n",
    "labels = hdb.labels_.tolist()\n",
    "\n",
    "assigned_poses = 0\n",
    "\n",
    "cluster_to_poses = {}\n",
    "for i, cluster_id in enumerate(labels):\n",
    "    if cluster_id not in cluster_to_poses:\n",
    "        cluster_to_poses[cluster_id] = [i]\n",
    "    else:\n",
    "        cluster_to_poses[cluster_id].append(i)\n",
    "        \n",
    "# Build an alternative, filtered movelet set that is\n",
    "# filtered down to just one movelet per track in a cluster\n",
    "# i.e., when more than one pose per track is in a given\n",
    "# cluster, just keep the first one. This has the effect\n",
    "# of stripping out repeated poses that are part of the\n",
    "# same low-motion movelet.\n",
    "\n",
    "filtered_movelet_indices = []\n",
    "\n",
    "tracks_per_cluster = []\n",
    "poses_per_track_per_cluster = []\n",
    "        \n",
    "for cluster_id in range(-1, max(labels) + 1):\n",
    "    # print(\"Poses in cluster\", cluster_id, labels.count(cluster_id))\n",
    "\n",
    "    cluster_track_poses = {}\n",
    "    for movelet_id in cluster_to_poses[cluster_id]:\n",
    "        movelet_track = frozen_movelets.iloc[movelet_id]['track_id']\n",
    "        if movelet_track not in cluster_track_poses:\n",
    "            if cluster_id != -1:\n",
    "                filtered_movelet_indices.append(movelet_id)\n",
    "            cluster_track_poses[movelet_track] = 1 # Include non-clustered poses?\n",
    "        else:\n",
    "            cluster_track_poses[movelet_track] += 1\n",
    "            \n",
    "    if cluster_id != -1:\n",
    "        assigned_poses += labels.count(cluster_id)\n",
    "        tracks_per_cluster.append(len(cluster_track_poses))\n",
    "        poses_per_track_per_cluster.append(labels.count(cluster_id) / len(cluster_track_poses))\n",
    "    \n",
    "    # print(\"Tracks in cluster\", cluster_id, len(cluster_track_poses))\n",
    "\n",
    "print(\"assigned\", assigned_poses, \"poses out of\", len(labels), round(assigned_poses/len(labels),4))\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], c=labels, cmap='Spectral', s=4)\n",
    "\n",
    "fig2 = plt.figure(figsize=(10,4))\n",
    "ax = fig2.gca()\n",
    "n, bins, patches = plt.hist(tracks_per_cluster, bins=20)\n",
    "ax.set_title(\"Tracks per cluster\")\n",
    "ax.set_xlabel(\"# Tracks\")\n",
    "ax.set_ylabel(\"# Clusters\")\n",
    "plt.show()\n",
    "\n",
    "fig3 = plt.figure(figsize=(10,4))\n",
    "ax = fig3.gca()\n",
    "n, bins, patches = plt.hist(poses_per_track_per_cluster, bins=30)\n",
    "ax.set_title(\"Poses per track per cluster\")\n",
    "ax.set_xlabel(\"Poses/track\")\n",
    "ax.set_ylabel(\"# Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the full pose data for each representative movelet from a track in a cluster,\n",
    "# to be used to display armatures and source image excerpts in the cluster plot and\n",
    "# in visualizations of the cluster averages\n",
    "\n",
    "print(len(filtered_movelet_indices))\n",
    "\n",
    "filtered_movelet_counts = dict()\n",
    "for i in filtered_movelet_indices:\n",
    "    filtered_movelet_counts[i] = filtered_movelet_counts.get(i, 0) + 1\n",
    "\n",
    "print(\"Filtered movelets:\",len(set(filtered_movelet_indices)))\n",
    "filtered_movelets = frozen_movelets.iloc[list(set(filtered_movelet_indices))]\n",
    "filtered_movelets.reset_index(inplace=True)\n",
    "filtered_poses = filtered_movelets['norm'].tolist()\n",
    "filtered_poses = [np.nan_to_num(pose, nan=-1) for pose in filtered_poses]\n",
    "len(filtered_poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"visualizing UMAP preclustered model\")\n",
    "show_poses = True\n",
    "plot_images = True\n",
    "\n",
    "if show_poses:\n",
    "    ord_cluster_to_poses = res = OrderedDict(sorted(cluster_to_poses.items(), key = lambda x : len(x[1]), reverse=True)).keys()\n",
    "    for cluster_id in ord_cluster_to_poses:\n",
    "        cluster_poses = []\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(UPSCALE * 100 / fig.dpi, UPSCALE * 100 / fig.dpi)\n",
    "        fig.canvas.draw()\n",
    "        print(\"CLUSTER:\", cluster_id, \"POSES:\", len(cluster_to_poses[cluster_id]))\n",
    "        for pose_index in cluster_to_poses[cluster_id]:\n",
    "            cl_pose = frozen_poses[pose_index]\n",
    "            cl_pose[cl_pose==-1] = np.nan\n",
    "            cluster_poses.append(cl_pose)\n",
    "        cluster_average = np.nanmean(np.array(cluster_poses), axis=0).tolist()\n",
    "        armature_prevalences = get_armature_prevalences(cluster_poses)\n",
    "        cluster_average = np.array_split(cluster_average, len(cluster_average) / 2)\n",
    "        #print(\"Average pose in cluster\", cluster_id, cluster_average)\n",
    "        cluster_average_img = draw_normalized_and_unflattened_pose(\n",
    "            cluster_average, armature_prevalences=armature_prevalences\n",
    "        )\n",
    "        #plt.figure(figsize=(2,2))\n",
    "        plt.imshow(cluster_average_img)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "fig = plt.figure(figsize=(40,40))\n",
    "ax = fig.gca()\n",
    "cm = colormaps[\"Spectral\"]\n",
    "norm = colors.Normalize(vmin=-1, vmax=max(labels))\n",
    "\n",
    "if plot_images:\n",
    "    \n",
    "    ax.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], alpha=0)\n",
    "    for i, cluster_id in enumerate(labels):\n",
    "        if cluster_id == -1:\n",
    "            continue\n",
    "        cl_pose = frozen_poses[i]\n",
    "        cl_pose[cl_pose==-1] = np.nan\n",
    "        cluster_pose = np.array_split(cl_pose, len(cl_pose) / 2)\n",
    "        cluster_pose_img = draw_normalized_and_unflattened_pose(\n",
    "            cluster_pose, armature_prevalences=[1] * 19\n",
    "        )\n",
    "        #img = Image.fromarray(img_region)\n",
    "        img = cluster_pose_img\n",
    "        img.thumbnail((40, 40), resample=Image.Resampling.LANCZOS)\n",
    "        ab = AnnotationBbox(OffsetImage(np.asarray(img)), (clusterable_embedding[i, 0], clusterable_embedding[i, 1]), frameon=False)\n",
    "        #ab.patch.set_linewidth(0)\n",
    "        #ab.patch.set(color=cm(norm(cluster_id)))\n",
    "\n",
    "        ax.add_artist(ab)\n",
    "else:\n",
    "    ax.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], c=labels, cmap='Spectral', s=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_embedding = umap.UMAP(\n",
    "    random_state=42,\n",
    ").fit_transform(filtered_poses)\n",
    "\n",
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], s=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterable_embedding = umap.UMAP(\n",
    "    n_neighbors=10,\n",
    "    min_dist=1.0,\n",
    "    n_components=2,\n",
    "    random_state=42,\n",
    ").fit_transform(filtered_poses)\n",
    "\n",
    "plt.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], s=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fitting clustering model\")\n",
    "\n",
    "hdb = HDBSCAN(min_cluster_size=3, min_samples=4) # , max_cluster_size=15\n",
    "hdb.fit(filtered_poses)\n",
    "labels = hdb.labels_.tolist()\n",
    "\n",
    "assigned_poses = 0\n",
    "\n",
    "cluster_to_poses = {}\n",
    "for i, cluster_id in enumerate(labels):\n",
    "    if cluster_id not in cluster_to_poses:\n",
    "        cluster_to_poses[cluster_id] = [i]\n",
    "    else:\n",
    "        cluster_to_poses[cluster_id].append(i)\n",
    "\n",
    "tracks_per_cluster = []\n",
    "poses_per_track_per_cluster = []\n",
    "        \n",
    "for cluster_id in range(-1, max(labels) + 1):\n",
    "    # print(\"Poses in cluster\", cluster_id, labels.count(cluster_id))\n",
    "\n",
    "    cluster_track_poses = {}\n",
    "    for movelet_id in cluster_to_poses[cluster_id]:\n",
    "        movelet_track = filtered_movelets.iloc[movelet_id]['track_id']\n",
    "        if movelet_track not in cluster_track_poses:\n",
    "            cluster_track_poses[movelet_track] = 1\n",
    "        else:\n",
    "            cluster_track_poses[movelet_track] += 1\n",
    "            \n",
    "    if cluster_id != -1:\n",
    "        assigned_poses += labels.count(cluster_id)\n",
    "        tracks_per_cluster.append(len(cluster_track_poses))\n",
    "        poses_per_track_per_cluster.append(labels.count(cluster_id) / len(cluster_track_poses))\n",
    "    \n",
    "    # print(\"Tracks in cluster\", cluster_id, len(cluster_track_poses))\n",
    "\n",
    "print(\"assigned\", assigned_poses, \"poses out of\", len(labels), round(assigned_poses/len(labels),4))\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], c=labels, cmap='Spectral', s=4)\n",
    "\n",
    "fig2 = plt.figure(figsize=(10,4))\n",
    "ax = fig2.gca()\n",
    "n, bins, patches = plt.hist(tracks_per_cluster, bins=20)\n",
    "ax.set_title(\"Tracks per cluster\")\n",
    "ax.set_xlabel(\"# Tracks\")\n",
    "ax.set_ylabel(\"# Clusters\")\n",
    "plt.show()\n",
    "\n",
    "fig3 = plt.figure(figsize=(10,4))\n",
    "ax = fig3.gca()\n",
    "n, bins, patches = plt.hist(poses_per_track_per_cluster, bins=30)\n",
    "ax.set_title(\"Poses per track per cluster\")\n",
    "ax.set_xlabel(\"Poses/track\")\n",
    "ax.set_ylabel(\"# Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fitting UMAP preclustered model\")\n",
    "\n",
    "hdb = HDBSCAN(min_cluster_size=3, min_samples=4) # , max_cluster_size=15\n",
    "hdb.fit(clusterable_embedding)\n",
    "labels = hdb.labels_.tolist()\n",
    "\n",
    "assigned_poses = 0\n",
    "\n",
    "cluster_to_poses = {}\n",
    "for i, cluster_id in enumerate(labels):\n",
    "    if cluster_id not in cluster_to_poses:\n",
    "        cluster_to_poses[cluster_id] = [i]\n",
    "    else:\n",
    "        cluster_to_poses[cluster_id].append(i)\n",
    "        \n",
    "# Build an alternative, filtered movelet set that is\n",
    "# filtered down to just one movelet per track in a cluster\n",
    "# i.e., when more than one pose per track is in a given\n",
    "# cluster, just keep the first one. This has the effect\n",
    "# of stripping out repeated poses that are part of the\n",
    "# same low-motion movelet.\n",
    "\n",
    "filtered_movelet_indices = []\n",
    "\n",
    "tracks_per_cluster = []\n",
    "poses_per_track_per_cluster = []\n",
    "        \n",
    "for cluster_id in range(-1, max(labels) + 1):\n",
    "    # print(\"Poses in cluster\", cluster_id, labels.count(cluster_id))\n",
    "\n",
    "    cluster_track_poses = {}\n",
    "    for movelet_id in cluster_to_poses[cluster_id]:\n",
    "        movelet_track = filtered_movelets.iloc[movelet_id]['track_id']\n",
    "        if movelet_track not in cluster_track_poses:\n",
    "            if cluster_id != -1:\n",
    "                filtered_movelet_indices.append(movelet_id)\n",
    "            cluster_track_poses[movelet_track] = 1 # Include non-clustered poses?\n",
    "        else:\n",
    "            cluster_track_poses[movelet_track] += 1\n",
    "            \n",
    "    if cluster_id != -1:\n",
    "        assigned_poses += labels.count(cluster_id)\n",
    "        tracks_per_cluster.append(len(cluster_track_poses))\n",
    "        poses_per_track_per_cluster.append(labels.count(cluster_id) / len(cluster_track_poses))\n",
    "    \n",
    "    # print(\"Tracks in cluster\", cluster_id, len(cluster_track_poses))\n",
    "\n",
    "print(\"assigned\", assigned_poses, \"poses out of\", len(labels), round(assigned_poses/len(labels),4))\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], c=labels, cmap='Spectral', s=4)\n",
    "\n",
    "fig2 = plt.figure(figsize=(10,4))\n",
    "ax = fig2.gca()\n",
    "n, bins, patches = plt.hist(tracks_per_cluster, bins=20)\n",
    "ax.set_title(\"Tracks per cluster\")\n",
    "ax.set_xlabel(\"# Tracks\")\n",
    "ax.set_ylabel(\"# Clusters\")\n",
    "plt.show()\n",
    "\n",
    "fig3 = plt.figure(figsize=(10,4))\n",
    "ax = fig3.gca()\n",
    "n, bins, patches = plt.hist(poses_per_track_per_cluster, bins=30)\n",
    "ax.set_title(\"Poses per track per cluster\")\n",
    "ax.set_xlabel(\"Poses/track\")\n",
    "ax.set_ylabel(\"# Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"visualizing UMAP preclustered model\")\n",
    "show_poses = False\n",
    "plot_images = False\n",
    "save_images = True\n",
    "\n",
    "if show_poses:\n",
    "    ord_cluster_to_poses = res = OrderedDict(sorted(cluster_to_poses.items(), key = lambda x : len(x[1]), reverse=True)).keys()\n",
    "    for cluster_id in ord_cluster_to_poses:\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(UPSCALE * 100 / fig.dpi, UPSCALE * 100 / fig.dpi)\n",
    "        fig.canvas.draw()\n",
    "        \n",
    "        cluster_poses = []\n",
    "        print(\"CLUSTER:\", cluster_id, \"POSES:\", len(cluster_to_poses[cluster_id]))\n",
    "        for pose_index in cluster_to_poses[cluster_id]:\n",
    "            cl_pose = filtered_poses[pose_index]\n",
    "            cl_pose[cl_pose==-1] = np.nan\n",
    "            cluster_poses.append(cl_pose)\n",
    "        cluster_average = np.nanmean(np.array(cluster_poses), axis=0).tolist()\n",
    "        armature_prevalences = get_armature_prevalences(cluster_poses)\n",
    "        cluster_average = np.array_split(cluster_average, len(cluster_average) / 2)\n",
    "        #print(\"Average pose in cluster\", cluster_id, cluster_average)\n",
    "        cluster_average_img = draw_normalized_and_unflattened_pose(\n",
    "            cluster_average, armature_prevalences=armature_prevalences\n",
    "        )\n",
    "        #plt.figure(figsize=(2,2))\n",
    "        plt.imshow(cluster_average_img)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "ax = fig.gca()\n",
    "cm = colormaps[\"Spectral\"]\n",
    "norm = colors.Normalize(vmin=-1, vmax=max(labels))\n",
    "\n",
    "if save_images:\n",
    "    images_dir = f\"pose_images/{video_name}\"\n",
    "    if not os.path.isdir(\"pose_images\"):\n",
    "        os.mkdir(\"pose_images\")\n",
    "    if not os.path.isdir(images_dir):\n",
    "        os.mkdir(images_dir)\n",
    "    img_metadata_file = open(f\"{video_name}.csv\", \"w\", encoding=\"utf-8\")\n",
    "    \n",
    "    # PixPlot metadata elements: \n",
    "    # year is an integer but doesn't need to be a year\n",
    "    # label can be the cluster the pose is in\n",
    "    # description is plain text\n",
    "    # can also supply any number of \"tags\", but it's not clear how these would be useful\n",
    "    img_metadata_file.write(\",\".join([\"filename\", \"description\", \"year\", \"label\"]) + \"\\n\")\n",
    "    \n",
    "    features_dir = f\"pose_features/{video_name}\"\n",
    "    if not os.path.isdir(\"pose_features\"):\n",
    "        os.mkdir(\"pose_features\")\n",
    "    if not os.path.isdir(features_dir):\n",
    "        os.mkdir(features_dir)\n",
    "    \n",
    "\n",
    "if plot_images or save_images:\n",
    "    ax.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], alpha=0)\n",
    "\n",
    "    for i, cluster_id in enumerate(labels):\n",
    "        #if cluster_id == -1:\n",
    "        #    continue\n",
    "\n",
    "        # Use this code block if we want to draw the normalized pose anywhere\n",
    "#         cl_pose = filtered_poses[i]\n",
    "#         cl_pose[cl_pose==-1] = np.nan\n",
    "#         cluster_pose = np.array_split(cl_pose, len(cl_pose) / 2)\n",
    "#         cluster_pose_img = draw_normalized_and_unflattened_pose(\n",
    "#             cluster_pose, armature_prevalences=[1] * 19\n",
    "#         )\n",
    "\n",
    "        cluster_movelet = filtered_movelets.iloc[i]\n",
    "        # Prefer a target frame in the middle of the movelet, but if the actual pose index\n",
    "        # is missing from this frame (which can happen sometimes), just use the first frame\n",
    "        # of the movelet\n",
    "        try:\n",
    "            target_frame = round((cluster_movelet['end_frame'] + cluster_movelet['start_frame']) / 2)\n",
    "            target_movelet = poses_df[(poses_df['frame'] == target_frame) & (poses_df['track_id'] == cluster_movelet['track_id'])]\n",
    "            if len(target_movelet) == 0:\n",
    "                target_frame = cluster_movelet['start_frame']\n",
    "                target_movelet = poses_df[(poses_df['frame'] == target_frame) & (poses_df['track_id'] == cluster_movelet['track_id'])]\n",
    "            target_pose = poses_df[(poses_df['frame'] == target_frame) & (poses_df['track_id'] == cluster_movelet['track_id'])].iloc[0]\n",
    "        except Exception as e:\n",
    "            print(\"Couldn't find representative pose from movelet middle or beginning, skipping\")\n",
    "            continue\n",
    "\n",
    "        save_name = f\"{images_dir}/{target_frame}_{target_pose['pose_idx']}.jpg\"\n",
    "\n",
    "        if not os.path.isfile(save_name):\n",
    "            \n",
    "            bbox = [round(v) for v in target_pose['bbox']]\n",
    "            print(\"frame\", target_frame, \"pose\", target_pose[\"pose_idx\"], \"pose bbox\", bbox)\n",
    "\n",
    "            frame_faces = await db.get_frame_faces(video_id, target_frame)\n",
    "\n",
    "            if len(frame_faces):\n",
    "                faces_df = pd.DataFrame.from_records(frame_faces, columns=frame_faces[0].keys())\n",
    "\n",
    "                target_face = faces_df[faces_df['pose_idx'] == target_pose['pose_idx']]\n",
    "                if (len(target_face)):\n",
    "                    target_face_df = target_face.iloc[0]\n",
    "                    face_bbox = [round(v) for v in target_face_df['bbox']]\n",
    "                    print(\"face_bbox\", face_bbox)\n",
    "\n",
    "                    min_x = min(bbox[0], face_bbox[0])\n",
    "                    min_y = min(bbox[1], face_bbox[1])\n",
    "                    max_x = max(bbox[0] + bbox[2], face_bbox[0] + face_bbox[2])\n",
    "                    max_y = max(bbox[1] + bbox[3], face_bbox[1] + face_bbox[3])\n",
    "                    b_w = max_x - min_x\n",
    "                    b_h = max_y - min_y\n",
    "\n",
    "                    # A bbox that includes the body and the face (if detected)\n",
    "                    bbox = [min_x, min_y, b_w, b_h]\n",
    "                    print(\"Combined bbox\", bbox)\n",
    "                \n",
    "            pose_frame_image = iio.imread(f\"/videos/{video_name}\", index=target_frame - 1, plugin=\"pyav\")\n",
    "\n",
    "            pose_img = Image.fromarray(pose_frame_image)\n",
    "\n",
    "            img_size = pose_img.size\n",
    "\n",
    "            pose_img = pose_img.resize((img_size[0] * UPSCALE, img_size[1] * UPSCALE))\n",
    "            drawing = ImageDraw.Draw(pose_img)\n",
    "            keypoints_triples = [(target_pose['keypoints'][i], target_pose['keypoints'][i+1], target_pose['keypoints'][i+2]) for i in range(0, len(target_pose['keypoints']), 3)]\n",
    "            drawing = draw_armatures(keypoints_triples, drawing)\n",
    "\n",
    "            pose_img = pose_img.resize(\n",
    "                (img_size[0], img_size[1]), resample=Image.Resampling.LANCZOS\n",
    "            )\n",
    "\n",
    "            cropped_pose_frame_image = pose_img.crop([bbox[0], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3]])\n",
    "\n",
    "            img = cropped_pose_frame_image\n",
    "\n",
    "            print(\"saving image\", save_name)\n",
    "            img.save(save_name)\n",
    "            \n",
    "            cropped_pose_frame_image.close()\n",
    "            pose_img.close()\n",
    "\n",
    "            # Assume there's always a features file if there's an image file\n",
    "            img_features = filtered_poses[i]\n",
    "            np.save(f\"{features_dir}/{target_frame}_{target_pose['pose_idx']}.npy\", img_features)\n",
    "            \n",
    "        else:\n",
    "            img = Image.open(save_name)\n",
    "            \n",
    "        frame_minute = round(target_frame / video_fps / 60)\n",
    "        \n",
    "        img_metadata_file.write(\",\".join([f\"{target_frame}_{target_pose['pose_idx']}.jpg\", f\"Frame {target_frame} | pose {target_pose['pose_idx']} | track {target_pose['track_id']}\", str(frame_minute), str(cluster_id)]) + \"\\n\")\n",
    "\n",
    "        if plot_images:\n",
    "            img.thumbnail((100, 100), resample=Image.Resampling.LANCZOS)\n",
    "            ab = AnnotationBbox(OffsetImage(np.asarray(img)), (clusterable_embedding[i, 0], clusterable_embedding[i, 1]), frameon=False)\n",
    "            #ab.patch.set_linewidth(0)\n",
    "            #ab.patch.set(color=cm(norm(cluster_id)))\n",
    "            ax.add_artist(ab)\n",
    "            ax.text(clusterable_embedding[i,0], clusterable_embedding[i, 1], cluster_id, color=\"red\") \n",
    "\n",
    "        img.close()\n",
    "\n",
    "    img_metadata_file.close()\n",
    "\n",
    "else:\n",
    "    ax.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], c=labels, cmap='Spectral', s=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_to_keep = set()\n",
    "\n",
    "with open(f\"{video_name}.csv\", \"r\", encoding=\"utf-8\") as img_metadata_file:\n",
    "    for la in img_metadata_file:\n",
    "        img_fn = la.strip().split(\",\")[0]\n",
    "        if img_fn == \"filename\":\n",
    "            continue\n",
    "        imgs_to_keep.add(img_fn)\n",
    "\n",
    "print(len(imgs_to_keep),\"unique images in metadata file\")\n",
    "        \n",
    "for fn in os.listdir(images_dir):\n",
    "    if os.path.isfile(f\"{images_dir}/{fn}\"):\n",
    "        if fn not in imgs_to_keep:\n",
    "            print(\"Deleting image\", fn)\n",
    "            os.unlink(f\"{images_dir}/{fn}\")\n",
    "            os.unlink(f\"{features_dir}/{fn.replace('jpg', 'npy')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
